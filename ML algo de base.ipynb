{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table des matieres"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [**Import Dataset**](#1.-Import-Dataset)\n",
    "2. [**Algorithmes ML de base**](## 2. Algorithmes ML de base)\n",
    "    1.  [Dataset Vehicules](#2.1-Dataset-Vehicules)\n",
    "    2.  [Dataset Caracteristiques](#2.2-Dataset-Caracteristiques)\n",
    "    3.  [Dataset Usager](#2.3-Dataset-Usager)\n",
    "    4.  [Dataset Lieux](#2.4-Dataset-Lieux)\n",
    "3. [**Supression des colonnes(variables)**](#3.-Supression-des-colonnes(variables))\n",
    "4. [**Gestion des Nan**](#4.-Gestion-des-Nan)\n",
    "    1. [Remplacement -1 par Nan](#4.-Gestion-des-Nan)\n",
    "    2.  [Dataset Vehicules](#4.2-Dataset-Vehicules)\n",
    "    3.  [Dataset Caracteristiques](#3.3-Dataset-Caracteristiques)\n",
    "    4.  [Dataset Usager](#4.4-Dataset-Usager)\n",
    "    5.  [Dataset Lieux](#4.4-Dataset-Lieux)\n",
    "5. [**Creation de variables suppl. et regroupement de categories**](#5.-Creation-de-variables-suppl.-et-regroupement-de-categories)\n",
    "    1.  [Dataset Vehicules](#5.1-Dataset-Vehicules)\n",
    "    2.  [Dataset Caracteristiques](#5.2-Dataset-Caracteristiques)\n",
    "    3.  [Dataset Usager](#5.3-Dataset-Usager)\n",
    "    4.  [Dataset Lieux](#5.4-Dataset-Lieux)\n",
    "6. [**Gestion des doublons**](#6.-Gestion-des-doublons)\n",
    "7. [**Sauvegarde dataset finale**](#7.-Sauvegarde-dataset-finale)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerome\\AppData\\Local\\Temp\\ipykernel_20192\\2487081710.py:14: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_2  =  pd.read_csv(path + \"lieux-\" + year + '.csv', delimiter=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset 2018-2021 :  (497594, 57)\n"
     ]
    }
   ],
   "source": [
    "path = 'data/'\n",
    "\n",
    "######\n",
    "years = ['2018f', '2019', '2020',  '2021' ]\n",
    "s_df = [\"carcteristiques\",\"lieux-\",\"vehicules-\",\"usagers-\"]\n",
    "dff = pd.DataFrame()\n",
    "k=0\n",
    "i=0\n",
    "hows='inner'\n",
    "######\n",
    "\n",
    "for year in years:\n",
    "    df_1 =   pd.read_csv(path + \"caracteristiques-\" + year + '.csv', delimiter=';')\n",
    "    df_2  =  pd.read_csv(path + \"lieux-\" + year + '.csv', delimiter=';')\n",
    "    df_3  =  pd.read_csv(path + \"vehicules-\" + year + '.csv', delimiter=';')\n",
    "    df_4 =   pd.read_csv(path + \"usagers-\" + year + '.csv', delimiter=';')\n",
    "\n",
    "    merged_df = pd.merge(df_1,      df_2,on=['Num_Acc'], how=hows)\n",
    "    merged_df = pd.merge(merged_df, df_3,on=['Num_Acc'], how=hows)\n",
    "    if year=='2018f':\n",
    "        df = pd.merge(merged_df, df_4,on=['Num_Acc','num_veh'], how=hows)\n",
    "    else:\n",
    "        df = pd.merge(merged_df, df_4,on=['Num_Acc','num_veh','id_vehicule'], how=hows)\n",
    "\n",
    "    dff = pd.concat([dff, df],ignore_index=True)\n",
    "    k=k+df.shape[0]\n",
    "    #print('year : ', year,df.shape)\n",
    "    i=i+1   \n",
    "print(\"Total dataset 2018-2021 : \",dff.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardisation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gest_dummies ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set / test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Algorithmes ML de classification supervisée de base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "clf = LogisticRegression (C=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "probs = clf.predict_proba(X_test)\n",
    "y_preds = np.where(probs[:,1]>0.4,1,0)\n",
    "cm = pd.crosstab(y_test, y_preds, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "\n",
    "fpr, tpr, seuils = roc_curve(y_test, probs[:,1], pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, color='orange', lw=2, label='Modèle clf (auc = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Aléatoire (auc = 0.5)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux faux positifs')\n",
    "plt.ylabel('Taux vrais positifs')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(gamma=0.01 , kernel='poly')\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred= clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametres = { \n",
    "    'C': [0.1,1,10], \n",
    "    'kernel' : ['rbf', 'linear','poly'],\n",
    "    'gamma' : [0.001, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_clf = GridSearchCV(estimator=clf, param_grid=parametres)\n",
    "grille = grid_clf.fit(X_train_scaled,y_train)\n",
    "\n",
    "print(pd.DataFrame.from_dict(grille.cv_results_).loc[:,['params', 'mean_test_score']]) \n",
    "grid_clf.best_params_ \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred= grid_clf.predict(X_test_scaled)\n",
    "confusion_matrix(y_test, y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "\n",
    "target=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "train_sizes, train_scores, valid_scores = learning_curve(svm.SVC(kernel='linear', C= 1), data, target, train_sizes=[50, 80, 110, 140], cv=5)\n",
    "\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "train_sizes=[50, 70, 80, 100, 110, 118]\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    grid_clf, data, target, n_jobs=4, train_sizes=train_sizes)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.grid()\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=  KNeighborsClassifier(n_neighbors=7, p=2)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred= knn.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARBRE DE DECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "# from interactions import show_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tree = pd.read_csv('I:\\PYFILES\\merged_data_2018_2021_for_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour éviter le plantage lors du fit : passage de objet à integer/float\n",
    "\n",
    "# Remplacer les valeurs dans la colonne 'age_usagers'\n",
    "df_tree['age_usagers'] = df_tree['age_usagers'].replace(['0-13', '14-17','18-24', '25-34','35-44','45-54', '55-64', '65-74','75-plus'], [0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "\n",
    "# Remplacer les valeurs dans la colonne 'periode'\n",
    "df_tree['periode'] = df_tree['periode'].replace(['Matin', 'Après-midi','Soir', 'Nuit'], [0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la cible et matrice des features\n",
    "target = df_tree.grav                                       # Vecteur cible\n",
    "data = df_tree.drop(columns=['Num_Acc', 'grav'], axis=1)    # Matrice des Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des jeux d'apprentissage et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une instance d'arbre de décision, puis entrainement\n",
    "dt_clf = DecisionTreeClassifier(criterion ='entropy', max_depth=32, random_state=123)\n",
    "dt_clf.fit(X_train, y_train)   # Ajustement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction sur les données de test\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "# Matrice de confusion\n",
    "pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stockage dans l'array feats, des features (caratérisques) importantes (les plus déterminantes)\n",
    "feats = {}\n",
    "for feature, importance in zip(data.columns, dt_clf.feature_importances_):\n",
    "    feats[feature] = importance \n",
    "    \n",
    "# Transformation en fd, puis tri    \n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Importance'})\n",
    "importances.sort_values(by='Importance', ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.ensemble.RandomForestClassifier(n_jobs=-1, random_state=321 )\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "cm = pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = clf.predict_proba(X_test)\n",
    "y_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "\n",
    "skplt.metrics.plot_cumulative_gain(y_true=y_test, y_probas=y_probas)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VotingClassifier et Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf2 = RandomForestClassifier( random_state= 123)\n",
    "clf3 = LogisticRegression(max_iter=1000 )\n",
    "\n",
    "vclf =  VotingClassifier(estimators=[('clf1_knn', clf1), ('clf2_rfc', clf2), ('clf3_lg', clf3)], voting='hard')\n",
    "\n",
    "cv3 = KFold(n_splits=3, random_state=111, shuffle=True)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, vclf], ['KNN', 'Random Forest', 'Logistic Regression', 'Voting Classifier']):\n",
    "    scores = cross_validate(clf, X_train, y_train, cv=cv3, scoring=['accuracy','f1'])\n",
    "    print(\"[%s]: \\n Accuracy: %0.2f (+/- %0.2f)\" % (label, scores['test_accuracy'].mean(), scores['test_accuracy'].std()),\n",
    "          \"F1 score: %0.2f (+/- %0.2f)\" % (scores['test_f1'].mean(), scores['test_f1'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclf = StackingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', clf3)], final_estimator=clf3)\n",
    "\n",
    "scores = cross_validate(sclf, X_train, y_train, cv=cv3, scoring=['accuracy', 'f1'])\n",
    "    \n",
    "print(\"[StackingClassifier]: \\n Accuracy: %0.2f (+/- %0.2f)\\n\" % (scores['test_accuracy'].mean(), scores['test_accuracy'].std()),\n",
    "      \"F1 score: %0.2f (+/- %0.2f)\" % (scores['test_f1'].mean(), scores['test_f1'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vclf.fit(X_train, y_train)\n",
    "sclf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Acc :\", vclf.score(X_test, y_test))\n",
    "print(\"Acc :\", sclf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
